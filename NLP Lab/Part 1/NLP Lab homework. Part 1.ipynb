{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "name": "NLP Lab homework, Part 1. Abramov V.S. from M03-101a.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Py3 Research",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eulvfJWl7ueY"
      },
      "source": [
        "# Lab 1\n",
        "\n",
        "\n",
        "## Part 1: Bilingual dictionary induction and unsupervised embedding-based MT (30%)\n",
        "*Note: this homework is based on materials from yandexdataschool [NLP course](https://github.com/yandexdataschool/nlp_course/). Feel free to check this awesome course if you wish to dig deeper.*\n",
        "\n",
        "*Refined by [Nikolay Karpachev](https://www.linkedin.com/in/nikolay-karpachev-b0146a104/)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV4rIjxa7uei"
      },
      "source": [
        "**In this homework** **<font color='red'>YOU</font>** will make machine translation system without using parallel corpora, alignment, attention, 100500 depth super-cool recurrent neural network and all that kind superstuff.\n",
        "\n",
        "But even without parallel corpora this system can be good enough (hopefully), in particular for similar languages, e.g. Ukrainian and Russian. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idSYq2GU7uew"
      },
      "source": [
        "### Frament of the Swadesh list for some slavic languages\n",
        "\n",
        "The Swadesh list is a lexicostatistical stuff. It's named after American linguist Morris Swadesh and contains basic lexis. This lists are used to define subgroupings of languages, its relatedness.\n",
        "\n",
        "So we can see some kind of word invariance for different Slavic languages.\n",
        "\n",
        "\n",
        "| Russian         | Belorussian              | Ukrainian               | Polish             | Czech                         | Bulgarian            |\n",
        "|-----------------|--------------------------|-------------------------|--------------------|-------------------------------|-----------------------|\n",
        "| женщина         | жанчына, кабета, баба    | жінка                   | kobieta            | žena                          | жена                  |\n",
        "| мужчина         | мужчына                  | чоловік, мужчина        | mężczyzna          | muž                           | мъж                   |\n",
        "| человек         | чалавек                  | людина, чоловік         | człowiek           | člověk                        | човек                 |\n",
        "| ребёнок, дитя   | дзіця, дзіцёнак, немаўля | дитина, дитя            | dziecko            | dítě                          | дете                  |\n",
        "| жена            | жонка                    | дружина, жінка          | żona               | žena, manželka, choť          | съпруга, жена         |\n",
        "| муж             | муж, гаспадар            | чоловiк, муж            | mąż                | muž, manžel, choť             | съпруг, мъж           |\n",
        "| мать, мама      | маці, матка              | мати, матір, неня, мама | matka              | matka, máma, 'стар.' mateř    | майка                 |\n",
        "| отец, тятя      | бацька, тата             | батько, тато, татусь    | ojciec             | otec                          | баща, татко           |\n",
        "| много           | шмат, багата             | багато                  | wiele              | mnoho, hodně                  | много                 |\n",
        "| несколько       | некалькі, колькі         | декілька, кілька        | kilka              | několik, pár, trocha          | няколко               |\n",
        "| другой, иной    | іншы                     | інший                   | inny               | druhý, jiný                   | друг                  |\n",
        "| зверь, животное | жывёла, звер, істота     | тварина, звір           | zwierzę            | zvíře                         | животно               |\n",
        "| рыба            | рыба                     | риба                    | ryba               | ryba                          | риба                  |\n",
        "| птица           | птушка                   | птах, птиця             | ptak               | pták                          | птица                 |\n",
        "| собака, пёс     | сабака                   | собака, пес             | pies               | pes                           | куче, пес             |\n",
        "| вошь            | вош                      | воша                    | wesz               | veš                           | въшка                 |\n",
        "| змея, гад       | змяя                     | змія, гад               | wąż                | had                           | змия                  |\n",
        "| червь, червяк   | чарвяк                   | хробак, черв'як         | robak              | červ                          | червей                |\n",
        "| дерево          | дрэва                    | дерево                  | drzewo             | strom, dřevo                  | дърво                 |\n",
        "| лес             | лес                      | ліс                     | las                | les                           | гора, лес             |\n",
        "| палка           | кій, палка               | палиця                  | patyk, pręt, pałka | hůl, klacek, prut, kůl, pálka | палка, пръчка, бастун |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNM3_fjr7ue2"
      },
      "source": [
        "But the context distribution of these languages demonstrates even more invariance. And we can use this fact for our purposes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLppwa527ue6"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYBGKAUn7ue_"
      },
      "source": [
        "import gensim\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwGoVhRA7ufP"
      },
      "source": [
        "In this notebook we're going to use pretrained word vectors - FastText (original paper - https://arxiv.org/abs/1607.04606).\n",
        "\n",
        "You can download them from the official [website](https://fasttext.cc/docs/en/crawl-vectors.html). We're going to need embeddings for Russian and Ukrainian languages. Please use word2vec-compatible format (.text)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otFXWTxzlalo",
        "outputId": "7259639d-b7dc-42c9-9c23-7d7501000f48"
      },
      "source": [
        "# since I'm working from google colab it's more comfortable to load files from\n",
        "# google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1JjQv_97ufT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e26efba-a028-493c-cab0-ead2b0a493d0"
      },
      "source": [
        "%%time\n",
        "uk_emb_path = \"/content/drive/MyDrive/Colab Notebooks/girafe-ai assignments/Word vectors/cc.uk.300.vec\"\n",
        "uk_emb = KeyedVectors.load_word2vec_format(uk_emb_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 10min 1s, sys: 7.89 s, total: 10min 9s\n",
            "Wall time: 10min 12s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffzuept_7ufd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47f1fb01-21e5-47f7-c37b-e99030e21b7b"
      },
      "source": [
        "%%time\n",
        "ru_emb_path = \"/content/drive/MyDrive/Colab Notebooks/girafe-ai assignments/Word vectors/cc.ru.300.vec\"\n",
        "ru_emb = KeyedVectors.load_word2vec_format(ru_emb_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9min 59s, sys: 8.03 s, total: 10min 7s\n",
            "Wall time: 10min 8s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTkXfT0W7ufk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "716b054d-2197-4852-fb9e-2b5401f7b9c7"
      },
      "source": [
        "ru_emb.most_similar([ru_emb[\"август\"]], topn=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('август', 1.0),\n",
              " ('июль', 0.9383153915405273),\n",
              " ('сентябрь', 0.9240028858184814),\n",
              " ('июнь', 0.9222575426101685),\n",
              " ('октябрь', 0.9095538854598999),\n",
              " ('ноябрь', 0.8930036425590515),\n",
              " ('апрель', 0.8729087114334106),\n",
              " ('декабрь', 0.8652557730674744),\n",
              " ('март', 0.8545796275138855),\n",
              " ('февраль', 0.8401416540145874)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdBA8lcg7ufs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0783cc6c-225c-47db-964a-48de827d1e8f"
      },
      "source": [
        "uk_emb.most_similar([uk_emb[\"серпень\"]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('серпень', 0.9999999403953552),\n",
              " ('липень', 0.9096440076828003),\n",
              " ('вересень', 0.901697039604187),\n",
              " ('червень', 0.8992519378662109),\n",
              " ('жовтень', 0.8810408711433411),\n",
              " ('листопад', 0.8787633776664734),\n",
              " ('квітень', 0.8592804670333862),\n",
              " ('грудень', 0.8586863279342651),\n",
              " ('травень', 0.8408110737800598),\n",
              " ('лютий', 0.8256431818008423)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yJvcKXO7uf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72c43520-e367-49fc-9bc5-6f52e8471a63"
      },
      "source": [
        "ru_emb.most_similar([uk_emb[\"серпень\"]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Stepashka.com', 0.2757962942123413),\n",
              " ('ЖИЗНИВадим', 0.25203436613082886),\n",
              " ('2Дмитрий', 0.25048112869262695),\n",
              " ('2012Дмитрий', 0.24829231202602386),\n",
              " ('Ведущий-Алексей', 0.2443869560956955),\n",
              " ('Недопустимость', 0.24435284733772278),\n",
              " ('2Михаил', 0.23981399834156036),\n",
              " ('лексей', 0.23740756511688232),\n",
              " ('комплексн', 0.23695150017738342),\n",
              " ('персональ', 0.2368222028017044)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNdYAR1q7uf6"
      },
      "source": [
        "Load small dictionaries for correspoinding words pairs as trainset and testset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35d_DAK67uf8"
      },
      "source": [
        "def load_word_pairs(filename):\n",
        "    uk_ru_pairs = []\n",
        "    uk_vectors = []\n",
        "    ru_vectors = []\n",
        "    with open(filename, \"r\") as inpf:\n",
        "        for line in inpf:\n",
        "            uk, ru = line.rstrip().split(\"\\t\")\n",
        "            if uk not in uk_emb or ru not in ru_emb:\n",
        "                continue\n",
        "            uk_ru_pairs.append((uk, ru))\n",
        "            uk_vectors.append(uk_emb[uk])\n",
        "            ru_vectors.append(ru_emb[ru])\n",
        "    return uk_ru_pairs, np.array(uk_vectors), np.array(ru_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkNL602WHJyO"
      },
      "source": [
        "# !wget -O ukr_rus.train.txt http://tiny.cc/jfgecz\n",
        "# Wrong link giving error 404. I loaded this .txt files manually"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoclU6JcHCcn"
      },
      "source": [
        "# !wget -O ukr_rus.test.txt http://tiny.cc/6zoeez\n",
        "# This link was ok but for better reliability i loaded this one manually too"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05BqsdSK7ugD"
      },
      "source": [
        "uk_ru_train, X_train, Y_train = load_word_pairs(\"ukr_rus.train.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQOZw51r7ugL"
      },
      "source": [
        "uk_ru_test, X_test, Y_test = load_word_pairs(\"ukr_rus.test.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZBBNvpz7ugQ"
      },
      "source": [
        "## Embedding space mapping (0.3 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_Dhk5gL7ugS"
      },
      "source": [
        "Let $x_i \\in \\mathrm{R}^d$ be the distributed representation of word $i$ in the source language, and $y_i \\in \\mathrm{R}^d$ is the vector representation of its translation. Our purpose is to learn such linear transform $W$ that minimizes euclidian distance between $Wx_i$ and $y_i$ for some subset of word embeddings. Thus we can formulate so-called Procrustes problem:\n",
        "\n",
        "$$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$$\n",
        "or\n",
        "$$W^*= \\arg\\min_W ||WX - Y||_F$$\n",
        "\n",
        "where $||*||_F$ - Frobenius norm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acOjDdtL7ugY"
      },
      "source": [
        "$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$ looks like simple multiple linear regression (without intercept fit). So let's code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb-KN1be7uga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c25b8c0-893f-414e-c20b-342ab3ce45af"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# YOUR CODE HERE\n",
        "# mapping = ...\n",
        "# -------\n",
        "\n",
        "mapping = LinearRegression(fit_intercept=False)\n",
        "mapping.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7tqJwoY7ugf"
      },
      "source": [
        "Let's take a look at neigbours of the vector of word _\"серпень\"_ (_\"август\"_ in Russian) after linear transform."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31SrFSbn7ugi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef36d704-5632-4ca8-a693-df4087cb2788"
      },
      "source": [
        "august = mapping.predict(uk_emb[\"серпень\"].reshape(1, -1))\n",
        "ru_emb.most_similar(august)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('апрель', 0.8531432747840881),\n",
              " ('июнь', 0.8402522802352905),\n",
              " ('март', 0.8385884165763855),\n",
              " ('сентябрь', 0.8331484794616699),\n",
              " ('февраль', 0.8311208486557007),\n",
              " ('октябрь', 0.8278019428253174),\n",
              " ('ноябрь', 0.8243728280067444),\n",
              " ('июль', 0.8229618072509766),\n",
              " ('август', 0.8112280368804932),\n",
              " ('январь', 0.8022986650466919)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okSkjk597ugo"
      },
      "source": [
        "We can see that neighbourhood of this embedding consists of different months, but right variant is on the ninth place."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2uY6Y9B7ugt"
      },
      "source": [
        "As quality measure we will use precision top-1, top-5 and top-10 (for each transformed Ukrainian embedding we count how many right target pairs are found in top N nearest neighbours in Russian embedding space)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zptuho8LAfIE"
      },
      "source": [
        "def precision(pairs, mapped_vectors, topn=1):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        pairs = list of right word pairs [(uk_word_0, ru_word_0), ...]\n",
        "        mapped_vectors = list of embeddings after mapping from source embedding space to destination embedding space\n",
        "        topn = the number of nearest neighbours in destination embedding space to choose from\n",
        "    :returns:\n",
        "        precision_val, float number, total number of words for those we can find right translation at top K.\n",
        "    \"\"\"\n",
        "    assert len(pairs) == len(mapped_vectors)\n",
        "    num_matches = 0\n",
        "    for i, (_, ru) in enumerate(pairs):\n",
        "        # YOUR CODE HERE\n",
        "        word_metrcis_list = ru_emb.most_similar(\n",
        "            mapped_vectors[i].reshape(1, -1),\n",
        "            topn=topn\n",
        "        )\n",
        "        word_list = [word for word, metric in word_metrcis_list]\n",
        "        if ru in word_list:\n",
        "            num_matches += 1\n",
        "\n",
        "    precision_val = num_matches / len(pairs)\n",
        "    return precision_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duhj9hpv7ugy"
      },
      "source": [
        "assert precision([(\"серпень\", \"август\")], august, topn=5) == 0.0\n",
        "assert precision([(\"серпень\", \"август\")], august, topn=9) == 1.0\n",
        "assert precision([(\"серпень\", \"август\")], august, topn=10) == 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-iyd5gP7ug5"
      },
      "source": [
        "assert precision(uk_ru_test, X_test) == 0.0\n",
        "assert precision(uk_ru_test, Y_test) == 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-ssEJ3x7uhA"
      },
      "source": [
        "precision_top1 = precision(uk_ru_test, mapping.predict(X_test), 1)\n",
        "precision_top5 = precision(uk_ru_test, mapping.predict(X_test), 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K-hy7a6Ksn2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "612858f8-179b-45d6-fecf-502817059cf9"
      },
      "source": [
        "print(precision_top1)\n",
        "print(precision_top5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.628498727735369\n",
            "0.7913486005089059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf6Ou8bx7uhH"
      },
      "source": [
        "## Making it better (orthogonal Procrustean problem) (0.3 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oLs-drN7uhK"
      },
      "source": [
        "It can be shown (see original paper) that a self-consistent linear mapping between semantic spaces should be orthogonal. \n",
        "We can restrict transform $W$ to be orthogonal. Then we will solve next problem:\n",
        "\n",
        "$$W^*= \\arg\\min_W ||WX - Y||_F \\text{, where: } W^TW = I$$\n",
        "\n",
        "$$I \\text{- identity matrix}$$\n",
        "\n",
        "Instead of making yet another regression problem we can find optimal orthogonal transformation using singular value decomposition. It turns out that optimal transformation $W^*$ can be expressed via SVD components:\n",
        "$$X^TY=U\\Sigma V^T\\text{, singular value decompostion}$$\n",
        "$$W^*=UV^T$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KSaRJFGMFiJ"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdFQ7qti7uhL"
      },
      "source": [
        "def learn_transform(X_train, Y_train):\n",
        "    \"\"\" \n",
        "    :returns: W* : float matrix[emb_dim x emb_dim] as defined in formulae above\n",
        "    \"\"\"\n",
        "    # YOUR CODE GOES HERE\n",
        "    # compute orthogonal embedding space mapping\n",
        "    # mapping = ...\n",
        "    u_matrix, _, vt_matrix = np.linalg.svd(X_train.T @ Y_train)\n",
        "    mapping = u_matrix @ vt_matrix\n",
        "\n",
        "    return mapping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X7QfYDd7uhQ"
      },
      "source": [
        "W = learn_transform(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVOFYYa37uhX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eafcdd20-416f-4735-95e0-7b827549200f"
      },
      "source": [
        "ru_emb.most_similar([np.matmul(uk_emb[\"серпень\"], W)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('апрель', 0.8245131969451904),\n",
              " ('июнь', 0.805662989616394),\n",
              " ('сентябрь', 0.8055761456489563),\n",
              " ('март', 0.8032935261726379),\n",
              " ('октябрь', 0.7987102270126343),\n",
              " ('июль', 0.7946797013282776),\n",
              " ('ноябрь', 0.7939636707305908),\n",
              " ('август', 0.7938188910484314),\n",
              " ('февраль', 0.7923861145973206),\n",
              " ('декабрь', 0.7715375423431396)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r297sYP37uhb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33200e8f-5ad1-4eba-c203-3b83fb57e274"
      },
      "source": [
        "print(precision(uk_ru_test, np.matmul(X_test, W)))\n",
        "print(precision(uk_ru_test, np.matmul(X_test, W), 5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6437659033078881\n",
            "0.7989821882951654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvUZ72U5AfJg"
      },
      "source": [
        "## Unsupervised embedding-based MT (0.4 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLyuVfHBLrJn"
      },
      "source": [
        "Now, let's build our word embeddings-based translator!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPAURW1CMuP7"
      },
      "source": [
        "Firstly, download OPUS Tatoeba corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F80kUKzQMsDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "736c7b9e-b119-458c-a38e-6482124a1d21"
      },
      "source": [
        "!wget https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/mono/uk.txt.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-18 17:18:37--  https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/mono/uk.txt.gz\n",
            "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
            "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1819128 (1.7M) [application/gzip]\n",
            "Saving to: ‘uk.txt.gz’\n",
            "\n",
            "uk.txt.gz           100%[===================>]   1.73M  7.80MB/s    in 0.2s    \n",
            "\n",
            "2021-10-18 17:18:38 (7.80 MB/s) - ‘uk.txt.gz’ saved [1819128/1819128]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CGFZoxCUVf1"
      },
      "source": [
        "!gzip -d ./uk.txt.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MV3VvoVUX5U"
      },
      "source": [
        "with open('./uk.txt', 'r') as f:\n",
        "    uk_corpus = f.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU7nPVf0UhbI"
      },
      "source": [
        "# To save your time and CPU, feel free to use first 1000 sentences of the corpus\n",
        "uk_corpus = uk_corpus[:1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgxFBp2bmacr"
      },
      "source": [
        "Если разделять слова по пробелам, то будут возникать случаи, когда \"словом\" будет считаться его написание слитно с предшествующим/последующим знаком препинания. При этом эмбеддинги известны для слов и знаков препинания отдельно. Чтобы на примерах типа \"коледж,\" функция translate давала результат не \"UNK\", а \"колледж,\", требуется разделить \"коледж,\" на \"коледж\" и \",\". Потом перевести их, а затем склеить обратно. Для этого написаны две функции ниже."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3lwG8MLDzFf",
        "outputId": "55f3560c-56f8-4bf9-d678-d4154e91899f"
      },
      "source": [
        "# Any necessary preprocessing if needed\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# знаки пунктуации, пищущиеся со словами слитно\n",
        "punct_signs = ['.', '.\\n', ',', ',\\n', '?', '?\\n', '!', '!\\n', '»', '»\\n',\n",
        "               ';', ';\\n', '«']\n",
        "\n",
        "\n",
        "def split_punct(sentence):\n",
        "    changed_sent = list()\n",
        "    for word in sentence.split(\" \"):\n",
        "        changed_word = list()\n",
        "        for c in word:\n",
        "            if c in punct_signs[:-1]:\n",
        "                changed_word.append(\" \")\n",
        "                changed_word.append(c)\n",
        "            elif c == punct_signs[-1]:\n",
        "                changed_word.append(c)\n",
        "                changed_word.append(\" \")\n",
        "            else:\n",
        "                changed_word.append(c)\n",
        "\n",
        "        changed_sent.append(\"\".join(changed_word))\n",
        "\n",
        "    return \" \".join(changed_sent)\n",
        "\n",
        "\n",
        "def unsplit_punct(sentence):\n",
        "    changed_sent = list()\n",
        "    for word in sentence.split(\" \"):\n",
        "        if word in punct_signs[:-1] and len(changed_sent) > 0:\n",
        "            changed_sent[-1] += word\n",
        "        elif len(changed_sent) > 0 and changed_sent[-1] == punct_signs[-1]:\n",
        "            changed_sent[-1] += word\n",
        "        else:\n",
        "            changed_sent.append(word)\n",
        "        \n",
        "    return \" \".join(changed_sent)\n",
        "\n",
        "test_sent = \"«Скільки коштує ця носова хусточка?» — «Дев'яносто п'ять центів».\\n\"\n",
        "print(\"Original sentence: \" + test_sent)\n",
        "\n",
        "splitted_test_sent = split_punct(test_sent)\n",
        "print(\"Splitted sentence: \" + splitted_test_sent)\n",
        "\n",
        "unsplitted_test_sent = unsplit_punct(splitted_test_sent)\n",
        "print(\"Unsplitted sentence: \" + unsplitted_test_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence: «Скільки коштує ця носова хусточка?» — «Дев'яносто п'ять центів».\n",
            "\n",
            "Splitted sentence: « Скільки коштує ця носова хусточка ? » — « Дев'яносто п'ять центів » .\n",
            "\n",
            "Unsplitted sentence: «Скільки коштує ця носова хусточка?» — «Дев'яносто п'ять центів».\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGksC7l_NMi9"
      },
      "source": [
        "def translate(sentence):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        sentence - sentence in Ukrainian (str)\n",
        "    :returns:\n",
        "        translation - sentence in Russian (str)\n",
        "\n",
        "    * find ukrainian embedding for each word in sentence\n",
        "    * transform ukrainian embedding vector\n",
        "    * find nearest russian word and replace\n",
        "    \"\"\"\n",
        "    # YOUR CODE GOES HERE\n",
        "    translated = []\n",
        "    sentence = split_punct(sentence)\n",
        "    for uk_word in sentence.split(\" \"):\n",
        "        # no need for translating empty strings\n",
        "        if uk_word == '':\n",
        "            continue\n",
        "\n",
        "        # There are no embeddings for words that contain\n",
        "        # ' and  ’ in uk_emb. Instead there are embeddings\n",
        "        # for words without these symbols. For example,\n",
        "        # uk_emb has no idea about \"здоров'я\" but knows\n",
        "        # \"здоровя\". So we fix this by 2 following lines.\n",
        "        uk_word = uk_word.replace('\\'', '')\n",
        "        uk_word = uk_word.replace('’', '')\n",
        "\n",
        "        # try to find embedding in uk_emb for current uk_word\n",
        "        try:\n",
        "            translated.append(\n",
        "                ru_emb.most_similar(\n",
        "                    [np.matmul(uk_emb[uk_word], W)],\n",
        "                    topn=1\n",
        "                )[0][0]\n",
        "            )\n",
        "\n",
        "        except KeyError:\n",
        "            # This one fixes situations such as '.\\n', '?\\n'\n",
        "            # and so on. Since these expressions are equal in both\n",
        "            # russian and ukranian we can just use uk_word as translation\n",
        "            if uk_word in punct_signs[:-1]:\n",
        "                translated.append(uk_word)\n",
        "\n",
        "            else:\n",
        "                # Maybe there is embedding available for lower-case word?\n",
        "                uk_word = uk_word.lower()\n",
        "                try:\n",
        "                    translated.append(\n",
        "                        ru_emb.most_similar(\n",
        "                            [np.matmul(uk_emb[uk_word], W)],\n",
        "                            topn=1\n",
        "                        )[0][0]\n",
        "                    )\n",
        "\n",
        "                except KeyError:\n",
        "                    translated.append(\"UNK\")\n",
        "\n",
        "    translated = \" \".join(translated)\n",
        "    return unsplit_punct(translated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hbbMy-tNxlf"
      },
      "source": [
        "assert translate(\".\") == \".\"\n",
        "assert translate(\"1, 3\") == \"1, 3\"\n",
        "assert translate(\"кіт зловив мишу\") == \"кот поймал мышку\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia6I2ce7O_HI"
      },
      "source": [
        "Now you can play with your model and try to get as accurate translations as possible. **Note**: one big issue is out-of-vocabulary words. Try to think of various ways of handling it (you can start with translating each of them to a special **UNK** token and then move to more sophisticated approaches). Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap1W7ZCeOAVU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74f108aa-dacc-48e4-e810-f05ca9479b3d"
      },
      "source": [
        "for ind, sent in enumerate(uk_corpus[::10]):\n",
        "    i = ind + 1\n",
        "    if i < 10:\n",
        "        sep = \" \" * 3\n",
        "    elif i < 100:\n",
        "        sep = \" \" * 4\n",
        "    elif i < 1000:\n",
        "        sep = \" \" * 5\n",
        "\n",
        "    print(f\"{i}. Перевод: \" + translate(sent), \"Оригинал: \" + sent, sep=sep)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Перевод: Я уже закончу колледж, когда мы прибежишь со Америки.\n",
            "   Оригинал: Я вже закінчу коледж, коли ви вернетеся з Америки.\n",
            "\n",
            "2. Перевод: Город бомбили враждебные самолеты.\n",
            "   Оригинал: Місто бомбардували ворожі літаки.\n",
            "\n",
            "3. Перевод: Возможно, мной антисоциальный, конечно это не означает, что мной не общаюсь со людьми.\n",
            "   Оригинал: Можливо, я антисоціальний, але це не означає, що я не спілкуюся з людьми.\n",
            "\n",
            "4. Перевод: Впрочем утра выпала роса.\n",
            "   Оригинал: Цього ранку випала роса.\n",
            "\n",
            "5. Перевод: Беда не приходит одна.\n",
            "   Оригинал: Біда не приходить одна.\n",
            "\n",
            "6. Перевод: Посмотри по тот дым.\n",
            "   Оригинал: Подивися на той дим.\n",
            "\n",
            "7. Перевод: Я заказал два гамбургера.\n",
            "   Оригинал: Я замовив два гамбургера.\n",
            "\n",
            "8. Перевод: Я не хотел никого обидеть.\n",
            "   Оригинал: Я не хотів нікого образити.\n",
            "\n",
            "9. Перевод: Гора покрыта снегом.\n",
            "   Оригинал: Гора вкрита снігом.\n",
            "\n",
            "10. Перевод: по фотографии во девушки корона не со золота, а со цветов.\n",
            "    Оригинал: На фотографії в дівчини корона не з золота, а з квітів.\n",
            "\n",
            "11. Перевод: Во меня То мечта.\n",
            "    Оригинал: У мене є мрія.\n",
            "\n",
            "12. Перевод: Я приехал во Японию со Китая.\n",
            "    Оригинал: Я приїхав у Японію з Китаю.\n",
            "\n",
            "13. Перевод: по север находится Шотландия; по юге — Англия; по востоке — Уэльс; и ещe дальше по востоке — северная Ирландия.\n",
            "    Оригинал: На півночі знаходиться Шотландія; на півдні — Англія; на заході — Уельс; і ще далі на заході — Північна Ірландія.\n",
            "\n",
            "14. Перевод: Его родная страна — Германия.\n",
            "    Оригинал: Його рідна країна — Німеччина.\n",
            "\n",
            "15. Перевод: Берн — столица Швейцарии.\n",
            "    Оригинал: Берн — столиця Швейцарії.\n",
            "\n",
            "16. Перевод: Он ждал по него к десятой часа.\n",
            "    Оригинал: Він чекав на нього до десятої години.\n",
            "\n",
            "17. Перевод: Ты можешь взять ту книгу даром.\n",
            "    Оригинал: Ти можеш взяти цю книгу даром.\n",
            "\n",
            "18. Перевод: Такой роман сочинил известный американский писатель.\n",
            "    Оригинал: Цей роман написав відомий американський письменник.\n",
            "\n",
            "19. Перевод: забронировать, будте ласковые, комнату возле международного аэропорта во Торонто.\n",
            "    Оригинал: Забронюйте, будьте ласкаві, кімнату біля міжнародного аеропорту в Торонто.\n",
            "\n",
            "20. Перевод: Он знает, что ты его влюбится?\n",
            "    Оригинал: Він знає, що ти його кохаєш?\n",
            "\n",
            "21. Перевод: Я знаю, что ты богатый.\n",
            "    Оригинал: Я знаю, що ти багатий.\n",
            "\n",
            "22. Перевод: Те, кто всё забывают, счастливые.\n",
            "    Оригинал: Ті, хто все забувають, щасливі.\n",
            "\n",
            "23. Перевод: Во этой реке опасно плавать.\n",
            "    Оригинал: В цій річці небезпечно плавати.\n",
            "\n",
            "24. Перевод: пришел, увидел, победил.\n",
            "    Оригинал: Прийшов, побачив, переміг.\n",
            "\n",
            "25. Перевод: Я хожу к школы пешком.\n",
            "    Оригинал: Я ходжу до школи пішки.\n",
            "\n",
            "26. Перевод: Не моя дело!\n",
            "    Оригинал: Не твоя справа!\n",
            "\n",
            "27. Перевод: Не забудь билет.\n",
            "    Оригинал: Не забудь квиток.\n",
            "\n",
            "28. Перевод: Кто он?\n",
            "    Оригинал: Хто він?\n",
            "\n",
            "29. Перевод: Вы будете чай ли кофе?\n",
            "    Оригинал: Ви будете чай чи каву?\n",
            "\n",
            "30. Перевод: Он не пойдет по пикник, как и мной.\n",
            "    Оригинал: Він не піде на пікнік, як і я.\n",
            "\n",
            "31. Перевод: Когда Вы родились?\n",
            "    Оригинал: Коли Ви народилися?\n",
            "\n",
            "32. Перевод: Это моя любимая песня.\n",
            "    Оригинал: Це моя улюблена пісня.\n",
            "\n",
            "33. Перевод: мы почти семья.\n",
            "    Оригинал: Ми майже сім’я.\n",
            "\n",
            "34. Перевод: Какой красивый сегодня месяц!\n",
            "    Оригинал: Який гарний сьогодні місяць!\n",
            "\n",
            "35. Перевод: Я против каких-либо войны.\n",
            "    Оригинал: Я проти будь-яких війн.\n",
            "\n",
            "36. Перевод: поверхность воздушной шары — UNK пространство, потому для неё не выполняются правила симметрической геометрии.\n",
            "    Оригинал: Поверхня повітряної кулі — неевклідовий простір, тому для неї не виконуються правила евклідової геометрії.\n",
            "\n",
            "37. Перевод: Говорят, что американцы считают количество денег, какую зарабатывает женщина, мерилом его умение.\n",
            "    Оригинал: Кажуть, що американці вважають кількість грошей, яку заробляє людина, мірилом його уміння.\n",
            "\n",
            "38. Перевод: Можно мной UNK это платье?\n",
            "    Оригинал: Можна я примірю це плаття?\n",
            "\n",
            "39. Перевод: Если будет красивая погода, мы доберёмся туда завтра.\n",
            "    Оригинал: Якщо буде гарна погода, ми доберемося туди завтра.\n",
            "\n",
            "40. Перевод: Это был злой заяц.\n",
            "    Оригинал: Це був злий заєць.\n",
            "\n",
            "41. Перевод: Один, два, три, четыре, пять-, восемь, семь, восемь, семдесят, десять.\n",
            "    Оригинал: Один, два, три, чотири, п'ять, шість, сім, вісім, дев'ять, десять.\n",
            "\n",
            "42. Перевод: Кто во любви не знает, тот горя не знает.\n",
            "    Оригинал: Хто в любові не знається, той горя не знає.\n",
            "\n",
            "43. Перевод: Его иметь волнуется за него.\n",
            "    Оригинал: Його мати хвилюється за нього.\n",
            "\n",
            "44. Перевод: Я уважаю тех, кто старается со всех сил.\n",
            "    Оригинал: Я поважаю тих, хто старається з усіх сил.\n",
            "\n",
            "45. Перевод: необычайная дружба переросла во глубокое любовь.\n",
            "    Оригинал: Їхня дружба переросла у глибоке кохання.\n",
            "\n",
            "46. Перевод: Рейчел пёт много молока каждый день.\n",
            "    Оригинал: Кейт п’є багато молока кожен день.\n",
            "\n",
            "47. Перевод: Он вор.\n",
            "    Оригинал: Він злодій.\n",
            "\n",
            "48. Перевод: шумового загрязнение можно было бы UNK только если бы люди были более чувствительны к окружающей среды.\n",
            "    Оригинал: Шумового забруднення можна було б позбігнути тільки якщо б люди були більш чутливими до навколишнього середовища.\n",
            "\n",
            "49. Перевод: чай со лимоном, будте ласковые.\n",
            "    Оригинал: Чай з лимоном, будьте ласкаві.\n",
            "\n",
            "50. Перевод: Не путать желание со влюбленностью.\n",
            "    Оригинал: Не плутай бажання з коханням.\n",
            "\n",
            "51. Перевод: Я бы со удовольствием сочинил сотни сложноподчинённые во UNK, конечно во меня То дела.\n",
            "    Оригинал: Я би з задоволенням написав сотні речень в Tatoeb’і, але в мене є справи.\n",
            "\n",
            "52. Перевод: Дайте мне чашечку кофе.\n",
            "    Оригинал: Дайте мені філіжанку кави.\n",
            "\n",
            "53. Перевод: ведь же ты никогда мне о это не рассказывала!\n",
            "    Оригинал: Але ж ти ніколи мені про це не розповідала!\n",
            "\n",
            "54. Перевод: Во тебя будут проблемы, если твои родители узнают.\n",
            "    Оригинал: У тебе будуть проблеми, якщо твої батьки довідаються.\n",
            "\n",
            "55. Перевод: Запах роз наполнил комнату.\n",
            "    Оригинал: Запах троянд наповнив кімнату.\n",
            "\n",
            "56. Перевод: Как во тебя дела?\n",
            "    Оригинал: Як у тебе справи?\n",
            "\n",
            "57. Перевод: Это мои штаны.\n",
            "    Оригинал: Це мої штани.\n",
            "\n",
            "58. Перевод: НЕт, спасибо.\n",
            "    Оригинал: Ні, дякую.\n",
            "\n",
            "59. Перевод: Я не понимаю, почему Германия победила по Евровидении.\n",
            "    Оригинал: Я не розумію, чому Німеччина перемогла на Євробаченні.\n",
            "\n",
            "60. Перевод: Добрый вечер.\n",
            "    Оригинал: Добрий вечір.\n",
            "\n",
            "61. Перевод: Со UNK Алексея Палашка поприветствовал президент Белоруссии Александр Лукашенко.\n",
            "    Оригинал: З юбілеєм Олексія Дударева привітав Президент Білорусі Олександр Лукашенко.\n",
            "\n",
            "62. Перевод: Млечный путь — широкий пояс со далеких звёзд, каждая звезда — солнце, такое как наше.\n",
            "    Оригинал: Чумацький шлях — широкий пояс із далеких зірок, кожна зірка — сонце, таке як наше.\n",
            "\n",
            "63. Перевод: удивительно видеть рок-звёзд со галстук!\n",
            "    Оригинал: Незвичайно бачити рок-зірок з краваткою!\n",
            "\n",
            "64. Перевод: всё печенье во форме звёзд.\n",
            "    Оригинал: Усе печиво у формі зірок.\n",
            "\n",
            "65. Перевод: ЧТо мне одеть — штаны ли юбку?\n",
            "    Оригинал: Що мені вдягнути — штани чи спідницю?\n",
            "\n",
            "66. Перевод: Краусс утверждал — известный московский скульптор.\n",
            "    Оригинал: Гартман Вітвер — відомий львівський скульптор.\n",
            "\n",
            "67. Перевод: Ой был злой кролик.\n",
            "    Оригинал: То був злий кролик.\n",
            "\n",
            "68. Перевод: Можешь взять любой, что тебе к отвратиться.\n",
            "    Оригинал: Можеш взяти будь-який, що тобі до сподоби.\n",
            "\n",
            "69. Перевод: Конечно мной пойду.\n",
            "    Оригинал: Звичайно я піду.\n",
            "\n",
            "70. Перевод: шелковичные прядут коконы.\n",
            "    Оригинал: Шовкопряди прядуть кокони.\n",
            "\n",
            "71. Перевод: ЧТо бы ты сделала, если бы во тебя было, замечу, десять тысяч долларов?\n",
            "    Оригинал: Що б ти зробила, якщо б у тебе було, скажім, десять тисяч доларів?\n",
            "\n",
            "72. Перевод: Он думает, что он кто-то, а действительно он никто.\n",
            "    Оригинал: Він думає, що він хтось, а насправді він ніхто.\n",
            "\n",
            "73. Перевод: она очень гордится своею коллекцией марок.\n",
            "    Оригинал: Вона дуже пишається своєю колекцією марок.\n",
            "\n",
            "74. Перевод: Он очень простой...\n",
            "    Оригинал: Він дуже простий...\n",
            "\n",
            "75. Перевод: Какая ты добра!\n",
            "    Оригинал: Яка ти добра!\n",
            "\n",
            "76. Перевод: Как мной за тобой соскучился!\n",
            "    Оригинал: Як я за тобою скучив!\n",
            "\n",
            "77. Перевод: Это всё, что мной знаю.\n",
            "    Оригинал: Це все, що я знаю.\n",
            "\n",
            "78. Перевод: Ты ведёшь дневник?\n",
            "    Оригинал: Ти ведеш щоденник?\n",
            "\n",
            "79. Перевод: Тебе решать.\n",
            "    Оригинал: Тобі вирішувати.\n",
            "\n",
            "80. Перевод: Это почта, а то — банк.\n",
            "    Оригинал: Це пошта, а то — банк.\n",
            "\n",
            "81. Перевод: Это всё, что мной хочу сделать.\n",
            "    Оригинал: Це все, що я хочу зробити.\n",
            "\n",
            "82. Перевод: Я впервые смотрю такой страшный фильм.\n",
            "    Оригинал: Я вперше дивлюся такий страшний фільм.\n",
            "\n",
            "83. Перевод: Этa песня напоминает мне о дом.\n",
            "    Оригинал: Ця пісня нагадує мені про дім.\n",
            "\n",
            "84. Перевод: Хироси здесь?\n",
            "    Оригинал: Хіросі тут?\n",
            "\n",
            "85. Перевод: Меня зовут Эдди.\n",
            "    Оригинал: Мене звуть Джек.\n",
            "\n",
            "86. Перевод: Как женщина живет, так она и умрет.\n",
            "    Оригинал: Як людина живе, так вона і помре.\n",
            "\n",
            "87. Перевод: Я здесь уже две часа.\n",
            "    Оригинал: Я тут уже дві години.\n",
            "\n",
            "88. Перевод: Мне надо извиниться перед Нб.\n",
            "    Оригинал: Мені треба вибачитись перед Ен.\n",
            "\n",
            "89. Перевод: Сегодня мной видел скворца.\n",
            "    Оригинал: Сьогодні я бачив шпака.\n",
            "\n",
            "90. Перевод: «Сколько стоить та носовая косыночка?» — «наверное пять- центов».\n",
            "    Оригинал: «Скільки коштує ця носова хусточка?» — «Дев'яносто п'ять центів».\n",
            "\n",
            "91. Перевод: солдаты медведи, как правило, очень опасные.\n",
            "    Оригинал: Ранені ведмеді, як правило, дуже небезпечні.\n",
            "\n",
            "92. Перевод: Он быстро устает.\n",
            "    Оригинал: Він швидко втомлюється.\n",
            "\n",
            "93. Перевод: остальные готовы.\n",
            "    Оригинал: Усі готові.\n",
            "\n",
            "94. Перевод: Он скучает по своей семьи.\n",
            "    Оригинал: Він скучає по своїй сім'ї.\n",
            "\n",
            "95. Перевод: «Спасибо», — «по здоровье».\n",
            "    Оригинал: «Дякую», — «На здоров'я».\n",
            "\n",
            "96. Перевод: Я ещe не знаю своего адреса, мной определенный момент буду жить во подруги.\n",
            "    Оригинал: Я ще не знаю своєї адреси, я певний час буду жити в подруги.\n",
            "\n",
            "97. Перевод: UNK вторая по длине река во мире после Нила.\n",
            "    Оригинал: Амазонка— друга по довжині ріка в світі після Ніла.\n",
            "\n",
            "98. Перевод: А если увидишь Тима, передай ему от меня поздравления.\n",
            "    Оригинал: А якщо побачиш Тома, передай йому від мене вітання.\n",
            "\n",
            "99. Перевод: закрой за собой дверь.\n",
            "    Оригинал: Закрий за собою двері.\n",
            "\n",
            "100. Перевод: Держи при себе словарь.\n",
            "     Оригинал: Тримай при собі словник.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me8_Fva3qKkY"
      },
      "source": [
        "В некоторых местах появляются UNK, что связано с единичными опечатками (например, \"Амазонка—\" вместо \"Амазонка —\"). Тем не менее, теперь такие ситуации сведены к минимуму."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3Ge_hVIhoMN"
      },
      "source": [
        "Great! \n",
        "See second notebook for the Neural Machine Translation assignment."
      ]
    }
  ]
}